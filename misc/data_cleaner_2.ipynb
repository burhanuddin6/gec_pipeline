{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AhmedAli\\anaconda3\\envs\\UGEC\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\AhmedAli\\anaconda3\\envs\\UGEC\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.11.0 and strictly below 2.14.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import urduhack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.array([x.strip() for x in open(\"file1.txt\", \"r\").readlines()])\n",
    "data2 = np.array([x.strip() for x in open(\"file2.txt\", \"r\").readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2045, 2045)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalizer(text):\n",
    "    new_text = \"\"\n",
    "    for char in text:\n",
    "        if char in \"0123456789\":\n",
    "            new_text += chr(ord(char) - ord('0') + ord('Û°'))\n",
    "        else:\n",
    "            new_text += char\n",
    "    return urduhack.normalization.normalize(new_text)\n",
    "\n",
    "normalizer = np.vectorize(normalizer)\n",
    "data1 = normalizer(data1)\n",
    "data2 = normalizer(data2)\n",
    "len(data1),len(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed = eval(open(\"allowed.txt\", \"r\").readline())\n",
    "allowed = set([chr(x) for x in allowed])\n",
    "clean_text = lambda text: \"\".join([c for c in text if c in allowed]).strip()\n",
    "clean_text = np.vectorize(clean_text)\n",
    "data1 = clean_text(data1)\n",
    "data2 = clean_text(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1998"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = []\n",
    "for d1, d2 in zip(data1, data2):\n",
    "    if d1 == d2:\n",
    "        continue\n",
    "    filtered_data.append((d1, d2))\n",
    "len(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"cleaned_wikiedit_corpus\", exist_ok=True)\n",
    "with open(\"cleaned_wikiedit_corpus/data1.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join([x[0] for x in filtered_data]))\n",
    "with open(\"cleaned_wikiedit_corpus/data2.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join([x[1] for x in filtered_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "!winrar a -r cleaned_wikiedit_corpus.rar cleaned_wikiedit_corpus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UGEC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
